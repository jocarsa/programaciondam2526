Y eh bueno, el objetivo de hoy consiste en crear una aplicación de inteligencia artificial utilizando Python más que nada porque voy a apuntar por aquí una serie de cosas, más que nada porque eh Python tiene librerías. Python tiene librerías. Las librerías eh aligeran la dificultad en la construcción de un software. Es como cuando hicimos el ejemplo del PDF, ¿vale? Cuando hicimos el ejemplo del PDF, nosotros decimos, "Oye, pues tal es una instancia de un nuevo PDF, te escribo no sé qué, sácamelo." Vale, fantástico. Pero no, espera, es que toda la dificultad está metida dentro de la librería. ¿Vale? Por esa razón, por esa razón, Python es una un lenguaje muy lento, porque es que realmente es muy lento, pero a la vez hace que el desarrollo paradójicamente sea muy rápido porque permite al usuario, entre comillas, perder poco tiempo. Porque gracias a esas librerías, como hemos utilizado un montón de librerías en este curso, pues gracias a las librerías podemos acelerar nuestra velocidad de desarrollo y luego eventualmente con un prototipo desarrollado podemos traducir el prototipo a otros lenguajes, digamos, más potentes. Vale, entonces, bueno, ahora hablaremos de que eh la potencia en el proceso de entrenamiento de un sistema de inteligencia artificial pues tiene su importancia, ¿vale? Así que de esta forma eh lo que vamos a hacer a continuación es utilizar una librería llamada Transformers. Nada que ver con los juguetes de la marca Hasbro, ¿vale? con los automóviles que se transforman en robots o viceversa, sino que los Transformers es una de las metodologías de entrenamiento de inteligencia artificial que está basada en la transformación dimensional de la información entrante. Transformación dimensional suena a algo muy rollo vengadores, ¿vale? No, dimensión quiere decir que cogemos elementos que son o bidimensionales y los convertimos en unidimensionales, una matriz unidimensional o viceversa. No os voy a enrollar con esto, aunque es un proceso muy interesante, porque de hecho en YouTube hay un montón de vídeos explicativos de la teoría de los Transformers y de hecho son vídeos animados que tienen esquemas muy guays y que permiten comprender de una forma muy sencilla cómo funcionan los Transformers, ¿vale? No es mi objetivo hoy. Mi objetivo hoy es más bien utilizar la librería Transformers. Eh, demostraros que podéis crear, podéis entrenar una inteligencia artificial conversacional de una forma razonablemente sencilla y luego quien haga este proceso y quien en un momento dado al tener dominado este proceso diga, "Hostia, qué guay, quiero saber más acerca de qué es esto de los Transformers. Quiero saber más acerca de qué hay debajo de esto. Pues en ese momento ya podéis bajar y ya podéis empezar a averiguar exactamente qué son los Transformers. No sabemos cuántos años durarán los Transformers en el sentido de que hace 5 años no se conocían y dentro de 5 años es posible que haya otra metodología o otra tecnología de entrenamiento de inteligencia artificial que sea mejor, digamos, que los Transformers. desaparecer. No creo que desaparezcan porque lo que está ocurriendo los últimos años es que las tecnologías se van agregando en el sentido de que aparece una nueva. Bueno, igual la nueva es mejor para unas tareas concretas, pero las metodologías antiguas existentes son mejores para otras tareas más concretas, ¿vale? Con lo cual, pues bueno, no creo que estemos hablando de que desaparezcan los Transformers en 5 años. Bien, así que como os digo, vamos a realizar un ejercicio en Python de entrenamiento de una inteligencia artificial. Voy a empezar con el mini hideg, ¿vale? Entonces, a partir de aquí lo que voy a hacer es que me voy a ir al mini high y voy a decir, eh, I would like to train a conversational artificial intelligence, ¿vale? Lo cual quiere decir varias cosas en esta frasecita, ¿vale? Hay un montón de cosas ahí puestas. ¿Qué cosas hay puestas? Bueno, pues un momento. Pues por una parte estamos hablando de entrenamiento. Cuando creamos un sistema de inteligencia artificial, algo que preguntabais el otro día en el grupo de WhatsApp, pues primero tenemos que entrenar a la inteligencia artificial. Segundo, tenemos que poner a prueba el entrenamiento, ¿vale? Tenemos que afinar la inteligencia artificial. Si la prueba es correcta, lanzamos la inteligencia artificial al público. Claro, a partir de aquí, ¿hasta qué punto una inteligencia artificial publicada está abierta a aprender más o no está abierta a aprender más? Como hoy vais a ver, depende de vosotros. Es decir, vamos a ver que el proceso de entrenamiento nos genera unos archivos llamados safe tensors, ¿vale? Tensores seguros, pero a partir de aquí, pues claro, depende del programador decir, "No, no, la inteligencia artificial publicada lee estos tensores, no escribe estos tensores, ¿vale? O como un ser humano podéis decir, "Bueno, tú acudes a la sociedad tras haberte educado y formado, pero a la vez cualquier ser humano acaba aprendiendo. Si quieres aprendes todos los días cosas nuevas, ¿vale? Con lo cual pues una vez más depende del eh del desarrollador, ¿vale? Eh, hay muchos tipos de inteligencia artificial, entonces voy a poner conversational, ¿vale? En este caso estamos hablando de una IA conversacional, que es una IA que se basa en preguntas y respuestas. ¿Vale? Claro, yo en un momento dado podría crear otro tipo de inteligencia artificial que fuera una inteligencia artificial basada en eh la generación de imágenes, imágenes generativas, pues en ese caso los Transformers no me valdrían tanto, ¿vale? Si quiero una IA generativa para IA conversacional, pues los Transformers van bien. Para una IA generativa, pues el modelo de difusión estable, stable diffusion, va bien o bien para una generativa o bien para lo contrario, ¿vale? Para una IA que reconozca patrones. Otra cuestión está en que si quiero una IA de visión artificial, pues está hay una librería que es muy conocida, que es la librería OpenCV, que sirve específicamente para esas cosas. ¿Vale? Entonces, a partir de aquí, como veis, esta frasecita, eh, cada palabra tiene su significado. Luego, evidentemente, una IA de inteligencia artificial. Y a partir de aquí voy a decirle, "Oye, ¿cómo quiero entrenarla?" Vale. E bueno, eh, in Python and I would like to use eh Jon eh files to train it. Vale. Eh, por ejemplo, ¿cómo podría ser? Pues voy a venir por aquí y voy a decir, mira, voy a hacer un sample, voy a hacer una muestra y digo eh elemento pregunta. Eh, esto es una pregunta. Una pregunta, ¿vale? Respuesta. Esto es una respuesta. Okay. Y ahora a continuación pues hago así, copio, pego, pego, pego y pongo aquí puntos suspensivos. Vale, en este caso, este es un modelo JSON muy típico y muy característico para un sistema de entrenamiento de inteligencia artificial. Si fuera un sistema de inteligencia artificial orientado a código, bueno, pues yo aquí pondría pregunta, respuesta y código. ¿Vale? podría poner una tercera propiedad dentro de cada uno de los objetos, pero en este caso quiero empezar con una inteligencia artificial. Vamos a empezar con algo sencillo y aún así ya veréis que de sencillo no tiene nada de pregunta y de respuesta, ¿vale? Por tanto, vamos con este JSON. Vamos a copiar esto. Eh, using this J template. Vale, eh, así que give me code to make the training y me code. Give me by code to make the test. face y luego una vez que pasemos la test face pues ya si queréis nos vamos a la fase de producción, pero la fase de producción me preocupa menos porque eso lo hemos hecho muchas veces. Básicamente es crear un frontend donde podamos hacer preguntas, un backend que procese las preguntas y me respuestas y ya está. Eso lo hemos hecho un montón de veces, ¿vale? Así que vamos allá. Lo difícil ahora veréis va a ser generar una base de conocimiento extensa, ¿vale? Una vez más, evidentemente, Chat GPT o Cloud o quien sea me va a ayudar con eso, pero bien, vamos a ver código en Python. Bueno, no le he dicho, por cierto, que quiero usar la librería de Transformers, pero con toda seguridad Chat GPT me va a decir, "¿Vas a utilizar la librería de Transformers?" porque es un clásico, pero mira, no se lo he dicho. A ver qué pasa. Es más, a ver qué me propone. Bien, vamos a ver. One way to build, ¿vale? Y eh vamos a ver. Basic retrieval system. Qué curioso, qué curioso. Bueno, Pickel. Uh, qué curioso. Pickel es una librería que sirve para poder escribir y leer archivos binarios. Wow. Wow. Vale. Eh, pues mira, no, no, eh, I would like something more advance, please. Advanced, please using eh Transformers Python Library. curioso, es muy estándar lo que os estoy contando hoy, con lo cual creía que ya de por sí me lo iba a proponer, pero en fin, da igual lo que sea, más que nada porque la librería de Transformers es una A ver, un momentín. Muy bien. Mira, por ejemplo, vale, para un modelo como GPT2, ojo, GPT2, ¿vale? El modelo más básico de chat GPT es el GPT4, pero da igual. Quiero decir, para un ejercicio de clase de hoy, aunque el ejercicio dure 6 horas, pero bueno, con un GPT2, pues ya podemos ir empezando a hacer cositas guay. Bien, vamos a ver. Using Transformers, ¿vale? Okay, esto ya es otra cosa. Bien. Sí, sí, sí, sí, sí, sí, sí, sí, sí, sí, sí, sí. Correcto. Eh, vamos a ver, vamos a ver. Te cuento, Fran, ahora que has comentado esto, eh, OpenI se basa en el modelo Nvidia, ¿vale? El modelo Nvidia en principio, ahora mismo, está siendo muy criticado porque eh son muy brutos, digamos, gastando recursos, ¿vale? Tanto por parte de OpenI como por parte de Nvidia. ¿Qué ocurre? Que OpenI te cobra 50 céntimos porque ellos consumen esa energía, esa electricidad. ¿Vale? ¿Qué ocurre? que los chinos, mira, noticia de hoy para que te hagas la idea, ¿vale? Tiene que ver con esto que me estás comentando, ¿eh? Mira, ya la han quitado de la portada. E Donald Trump Envidia H2O, procesador H2O. Vale, Trump causa envidia. Espérate, Vamos a ver aquí. Golpe de Trump Envidia. Perderá 5,500 millones tras prohibirle exportar a China un microchip. Donald Trump no le dejaba exportar a Nvidia sus microchips de alto rendimiento. Nvidia dijo, "Vale, pues mira, voy a hacer un microchip llamado H2 recortado para China, ¿vale? Más barato, más recortado." ¿Qué ocurre? Que Donald Trump a última hora ha dicho, "Mira, ¿sabes qué? El chip H2 tampoco lo vas a exportar." Bien, ¿qué ocurre? Pues que vamos a ver, pues que por aquí, bueno, estaba viendo una noticia que estaba viendo esta mañana por aquí decían, "El problema no es que Nvidia pierda 5500 millones por no poder vender chips a China. El problema es qué va a hacer China ahora porque como a China le dé por desarrollar un procesador sustitutivo del H2 o de los procesadores potentes de Nvidia y lo consigan y el procesador que desarrolle China sea más potente y más barato, no es que Nvidia vaya a perder 5500 millones, es que Nvidia va a caer, ¿vale? O sea, y si cae Nvidia, cae Estados Unidos, porque el poder de la supercomputación ya no estará en manos de Estados Unidos, ¿vale? Con lo cual, con lo cual eh, pues eso, o sea, Deepsik ya sorprendió a todo el mundo en el sentido de que Estados Unidos recorta exportaciones hacia China en cuanto a potencia de cálculo. ¿Qué hizo China? crear una inteligencia artificial con un consumo más óptimo de energía que Opene. Con esto lo que quiero decir es que en esta vida pues hay que pensar en las acciones y en las consecuencias, ¿vale? Y hay que pensar en que pues el los anteriores gobiernos de Estados Unidos veían a China como competidor muy fuerte, ¿vale? como adversario y decían, "Es mi adversario, es mi competidor, pero más vale que le venda yo y así mientras me compra no se distrae en desarrollar su propia tecnología." ¿Vale? Es decir, los anteriores eh gobernantes de Estados Unidos probablemente eran más malvados que Donald Trump desde el punto de vista de la hegemonía tecnológica estadounidense, pero eran más listos. Probablemente Donald Trump es más sincero, es más campechano, es más eh, no sé, es más proteccionista que quiere que lo que él dice, ¿no? Que América cuando dice América realmente quiere decir los Estados Unidos de América, ¿vale? Pero América sea grande, no se da cuenta de que América es todo un continente de arriba a abajo, pero bueno, para él América es Estados Unidos de América. Pero claro, el problema es que, o sea, la voluntad probablemente es buena. Pero como la inteligencia no le acompaña la voluntad, pues probablemente va a conseguir lo contrario de lo que quiere, ¿vale? Porque pues eso, los chinos están diciendo, "¿Qué pasa que me limitas las importaciones de chips?" No pasa nada, igual me hago el mío, igual desbanco al tuyo y entonces veremos quién está en problemas, ¿vale? O sea, que ya te digo, o sea, los españoles deberíamos estar haciendo lo mismo, pero no somos así. Españoles somos mucho más limitados. En fin, ¿qué se va a hacer? Bueno, pues vamos a voy a irme a JHub, voy a irme a repositorios, ¿vale? Vamos a seguro que en IA tengo un montón de Vale, IA 2024, pues vamos a eh IA 2025, IA 2025 o mira, inteligencia artificial. Oh, ya tengo esto. 2023. Pues sabes qué, Transformers. Hala, pues venga, pues Transformers. Okay, público. Readm. Vamos allá. Bien, así que bueno, me lo voy a clonar y file y clone y Transformers. No sé si habéis oído alguna vez ese refrán de que o ese refrán, os he dicho de que cuando alguien intenta fastidiar una persona, a veces se acaba fastidiando a sí mismo. O como decía mi madre cuando yo era pequeño, hijo mío, para ser malo hay que ser muy bueno. Hay que ser muy bueno siendo malo, ¿vale? Con lo cual yo le decía, "Ah, no entiendo qué quieres decir." Y mi madre decía, "Sí, lo que quiero decir es que para ser malo hay que ser muy bueno siendo malo." Me decía, "Hijo mío, y tú no lo eres." O sea, en plan de no lo intentes que no te va a salir. Vale, con lo cual pues eso, ¿no? A Trump yo creo que le pasa lo mismo y es que quiere ser, entre comillas malo, pero hay que ser muy bueno siendo malo. Y los anteriores que iban de buenos y realmente eran mucho más malos, digamos, que Trump yendo de buenos. En fin. el tema. Eh, vamos a copiar por aquí, vamos a ir a por aquí a idl, vamos a crear un nuevo archivo, ¿vale? Y eh vamos a ver, vamos a el modelo T5 Small, ¿vale? Un modelo muy limitado, como os digo, pero no pasa nada porque lo que queremos hoy no es algo muy avanzado, sino algo que sea ilustrativo. Bien, así que inteligencia FGH Jo, Transformers, perdón, OPQRs Ters. la leche aquí, ¿vale? Y entrenamiento, entrenamiento punto Python. Vale. Y aquí lo que ocurre es que vamos a pregunta respuesta, ¿vale? Okay. Por aquí y ya está, ¿vale? Y ya está. Y data jon. Vale, este es el entrenamiento. Ahora esto es el test de inferencia, ¿vale? Así que voy a esto y voy a crear, bueno, lo voy a guardar como prueba punto Python y Sí, sí, sí, exacto. Pero eh digamos la diferencia, ¿vale? Es que tu madre te decía lo que iba a pasar después. Es decir, eh, ¿sabes? Sé malo y el castigo que vas a recibir. Mi madre era como más preventiva, ¿vale? Más de ni lo intentes, no vales para eso, ¿vale? Vales para otras cosas, pero para ser malo no vales porque para ser malo pues hay que tener, ¿sabes?, pues una agilidad mental, una tal y mi madre me decía, "Tú, hijo mío, pues no tienes eso, no puede ser eso." Así que bueno, así que son dos formas de ver, digamos, el proceso, ¿no? Eh, ahora a continuación, ahora a continuación voy a hacer lo siguiente. E now create a minimal, bueno, minimal tampoco, no sea que me diga 10 preguntas, ¿sabes? Eh, a training JSON with questions and answers in Spanish about programming, ¿vale? Computer programming. Please make it as large as possible. Y está. Quiero decir, con que hagamos un primer entrenamiento de unas, no sé, sabes, 20 preguntitas, pues por lo menos ya podemos lanzar algo, ya podemos ejecutar algo. Eh, esta librería, la librería de P torch usará la GPU, ¿vale? Que el tema de computación en la GPU, como os decía antes, pues es algo que también tenemos que analizar, ¿vale? Pero ya os digo que ahora mismo, como vamos a usar la librería P Torch, pues la librería P Torch, eh, oh, la librería P Torch nos ayudará. Vale, vamos allá y eh vamos a por ello. Ey, muy bien. Pues mira, ¿qué es Python? ¿Cómo se está la node? Vale, Java C. Pues mira, esto, insisto que eh pues evidentemente llegados a este punto tenéis que pensar, oye, ¿para qué queréis eh entrenar esta inteligencia artificial? ¿Cómo la vamos a entrenar? Claro, vosotros diréis, "¿Y ahora cómo me curro yo un JS con miles de preguntas y respuestas?" Pues ahí está el problema, ¿vale? Esa es la cuestión. Hay muchas formas, evidentemente, de optimizar o de hacer más productivo la generación de un JSON, pero al final, como os digo, el Uy, ¿qué me dices? Eh, a ver, nothing showed on screen, please reelaborate. Y mira, incluso me puedo ir a cloud eh aquí. Vale. Eh, this is a training. Ahí, ahí, ahí, ahí, ahí, ahí, ahí, ahí, ahí. Vamos a ello. Sí, correcto. Eh, template in for a conversational AI. Please create as many questions and answers in Spanish as possible, please. Y pego. Vale, bien. Y sí, efectivamente, efectivamente. Correcto. Vale. en el momento, o sea, GitHub, Microsoft con Copilot juega con ventaja. Pero, ¿por qué GHub es gratuito? Por esa razón, porque nosotros estamos contribuyendo con nuestro código a alimentar a la inteligencia artificial de Microsoft. ¿Qué ha hecho Deepsic? Entrenar a su inteligencia artificial mediante preguntas y respuestas a chat GPT, ¿vale? Y obviamente también podemos hacer scraping en la web, por ejemplo, un scraping a Star Copow Overflow o un scraping a si quieres en la bestia a foro coches para obtener información, ¿vale? O sea, que sí, evidentemente el scrapeo de información automatizado pues es una forma de entrenar. No digo que la única forma de entrenar sea una persona o 1000 personas picando información a mano, sino que, vale, yo, por ejemplo, eh, yo tengo varios libros publicados, pues podría el PDF de cualquiera de los libros, meter la chat GPT y decirle, "Mira, en base a este PDF, générame preguntas y respuestas, pero en base a este PDF, lo único que tienes que hacer es leer este PDF." Vale, vamos a empezar con algo. energía renovable. ¿Me estás contando? No, no, no, no, no, no, no. Perdón, perdón, perdón, perdón. No, no, no. Para, para, para, para, para, para. no puedes parar. no se puede parar. Qué cachondo, ¿no? Eh, hola. Para a ver. Vale, mira, por aquí va. Pues venga, voy a esto. Vamos a meterlo por aquí. Vamos a ir a brackets. Vamos a meterlo como ah brackets, perdona, no headit. Es que las clases de la mañana uso brackets porque estoy en Windows por obligación, pero aquí pues no. Entonces, HTML y Transformers. Vamos a ver. Bueno, bueno. Eh, vamos a ver, vamos a ver, Fran. O sea, me alegra que ha dejes preguntas porque quiere decir que mentalmente estás tres pasos más adelante. O sea, estás pensando, "Vale, ¿qué va a pasar cuando yo lo haga? ¿Qué va a pasar? ¿De dónde saco la información?" Vale, eso que estás comentando se llama en inteligencia artificial se llama sesgo. Y ses quiere decir que la fiabilidad de la inteligencia artificial que entrenemos será la misma fiabilidad que tenga la fiabilidad, o sea, que tenga fiabilidad la información de entrada. Si le damos información correcta, información buena, información fiable, información veraz, la inteligencia artificial responderá verazmente. Si la alimentamos con, entre comillas, exageración, mentiras, pues la inteligencia artificial responderá mentiras. ¿Vale? Pero el tema del sesgo es mucho más complejo de lo que puede aparecer en un primer momento. ¿Por qué? Pues porque qué es verdad y qué es mentira no es algo objetivo, es algo muy discutible. ¿Vale? Por tanto, ahí entran eh ahora hablaremos de ello, entran cuestiones éticas de un calado filosófico, os lo aseguro muy profundo. Ahora vamos a poner esto en funcionamiento y ahora hablamos de ello. Entonces, eh, Transformers y voy a crear un archivo nuevo, data.json y pego el archivo data.json. En este caso es una inteligencia artificial muy eh muy inocente, ¿vale? Lo único que hace es hablar tonterías de programación. Vale, vamos a verlo y nos vamos a prueba, no, nos vamos a entrenamiento. Yo creo que ya. A la de BIM, a la BAM, a la BIM, bom, Bam. Me estoy asegurando, me estoy asegurando. No lo veo, pero vale. Bueno, igual me da un error de no de escritura, no, porque eso sería PHP. Vale, va F5. Bien, vamos a ver el procesador. Vamos a ver el procesador. Ay, Vale, ha dado error. Igual me dice que Oh, vale. Eh, okay. Ah, eh, sentence peace library que no se ha encontrado en tu entorno. Okay, perfecto. Vale, vamos a hacer así. Vamos a hacer así. La cuestión está, por ejemplo, has puesto un ejemplo muy bueno, has puesto un ejemplo, de hecho, que es cojonudo, que es el tema del descubrimiento de América. Claro, ¿quién descubrió América? Bueno, pues de forma oficial, aunque sin embargo accidental, la descubrió Cristóbal Colón, pero sin embargo eh hay registros de que siglos antes de Cristóbal Colón, los vikingos, quieras que no, a través de Groenlandia, pues llegaron a la parte de Norteamérica. Claro, ¿qué ocurre? que los vikingos no dijeron, "He descubierto un nuevo continente", pero desde otro punto de vista es un, entre comillas ciudadano. En aquel momento no existía la ciudadanía, ¿vale? Pero es un una persona de origen europeo visitando Estados Unidos, lo que hoy es Estados Unidos, el continente americano, sin saber siquiera que era otro continente y volviendo. Entonces, claro, ¿qué es la verdad? Pues es lo que te digo, es que la verdad es interpretable. No hay una sola verdad objetiva, indiscutible y aceptada y aceptable por todos los seres humanos. Vale, por eso es justo ese ejemplo que has puesto. Es muy bueno. Vale, vamos allá. Pip install trozos de frases. Me dirá que eh Oh, oh, me la ha instalado. Vale, pues okay. Vale. Conda force center. No, no, si usas con no uso cona. Vale, venga, fenomenal. Vamos a arrancar de nuevo. Entrenamiento F5 y a ver procesador, ¿cómo va? Okay, okay, okay, okay. Vale, entrenando. Ojo, 9% 13%. El procesador de momento no va muy allá, pero entiendo que debe ser porque la GPU está yendo un poquito a tope. Vale, 39%, 43%. Tú dirás, "Hostia, ¿qué está haciendo?" No, ¿qué está haciendo? porque han sido 20 frases, pero lo que está haciendo es crear los sensores. Vamos a ver. Ojo, 199 megas. Vale. Bueno, a ver qué ha hecho. A ver qué ha hecho. Vamos a ver. Me voy a HTML. Me voy a Transformers. No pasa nada porque haya fallado el proceso de entrenamiento. Transformers. Y no ha escrito ningún no ha escrito ningún temporal. Vale, eh. Okay. Pues y new problem. Vamos a ver. Okay. Actualizar. Vamos a probar. En primer lugar actualizar, no cuesta nada. Así que pip installizar. Actualizamos Transformers a la última versión. No creo que sea eso, pero vale, vamos a probarlo más que nada porque la librería que ya tenía instalada, yo creo que ya debía estar bastante actualizada, pero vamos a darle. No, eh. Okay. No, entonces, okay, okay, okay. Vale. Training de training arc y no. Okay. Oh, vale. Vamos a ver. Venga, va. Ah, claro, al actualizar una librería, pues tengo que actualizar la otra. Vamos a ver. Okay, okay, vale, vale. Vamos a ver si ahora Okay, venga, pues si todo ha ido bien. Si todo ha ido bien. Por cierto, el procesador ni se ha notado casi. Vale, si todo bien, nos vamos, ¿dónde nos vamos? Aquí y veremos que eh tengo chatbot model y tengo una serie de configation safe tensors y los safe tensors, como podéis ver, tienen 242 megas, ¿vale? Okay. Y resultados por aquí. Muy bien, muy bien, muy bien. Vamos a probarlo. Vamos a probarlo. Así que me vengo por aquí. Prueba. Vamos a ver. Chatbot model, ¿vale? Chat tokenizer. Y el main lo que hace es un input, ¿vale? F5. Lee el bot y dice, yo le digo, "¿Qué es Python?" y me dice, "¿Qué es Python? ¿Qué es Python? ¿Qué es Python?" Vale, okay. Y le digo Python. Y pregunta Python. Vale, un momentín, eh, momentín. A ver, voy a ver una pregunta concreta. ¿Será que es muy limitado? A ver, un momentín. Eh, leches, ¿dónde está Jita? Aquí. A ver, voy a preguntarle algo directamente. Ah, aquí. Vale. ¿Qué es el de Booging? No, no, algo pasa, algo pasa, algo pasa. Eh, something happens on testing. It just returns the question even with a absolute match. with the training JSON. Vamos a verlo. Ah, la fase de entrenamiento parece que está correcta, pero la fase de prueba no tanto. Vamos a ver. Cuando prueba el chat no está funcionando los inputs. Vale, vamos a ver. Vale, el entrenamiento está correcto. Pregunta, respuesta, pregunta, respuesta, pregunta, respuesta. Sí, vale. Número de épocas. Okay, vale. Vamos a aumentar el número de épocas y Okay, perfecto. Vale, vamos a un entrenamiento más duro. Me voy a entrenamiento y ajuste de la fase de diferencia. Vale, diversas y evitar tal. Okay, perfecto. Copiamos. Ahora esto es la prueba y vamos a probar. Vale, entrenamiento F5. Okay. Ah, evaluéis un strategy. Lo quito. También voy a quitar los archivos previos, ¿vale? Y vamos a darle. Esto es prueba. Esto es entrenamiento. Okay, okay, okay. Vale. Y ahora la prueba, ¿vale? Eh, ¿qué es Python? No. ¿Qué es Python? Pregunta, ¿qué es Python? ¿Qué es Python? ¿Qué es Python? Vale, de hecho, lo que ha aprendido es tacata. Vale, ¿qué es Java? Algo ha aprendido, pero muy poco. ¿Qué es Java? Él pregunta el esquinario para el ejemplo de esquincia con el esquincia y la pregunta y el e. O sea, bien, tengo una de entrenamiento, pero ya tengo un entrenamiento de inteligencia artificial. ¿Qué está haciendo? me está dando resultados eh, como diría yo, surrealistas, ininteligibles, pero no pasa nada porque ya hemos empezado a entrenar una inteligencia artificial, ¿vale? Evidentemente le tenemos que dar mucho más. Y en Apox, vamos a ver dónde están los apox, eh, un momentín. Mira, ves, usa CUDA si está disponible. Vale. Y eh vamos a ver. So answers are still mostly inintelligible. Inteligible. Please set the training process with more Apox to eh make a better training even if it costs more time to train. Vale, pero poco a poco, ¿vale? Ya tenemos que el programa con lo que le hemos alimentado está construyendo frases, aunque evidentemente, vale, algo que se hace en 5 minutos, pues no nos va a dar un resultado de madre, sino que tenemos que tunearlo, tenemos que afinarlo, tenemos que decirle, "No, vigílalo más, procésalo más, macho más, mastícalo más y aprende mejor y ya está." Luego, por otra parte, insisto, que le estamos dando un JS de mierdicilla, ¿vale? Tendríamos que darle un JS inmenso con un montón de preguntas y respuestas para que el programa las pudiera masticar y pudiera llegar a conclusiones válidas. Bien, vamos a ver. Vamos a ver. Vale, esto por aquí. Esto es entrenamiento, el valor es un strategi, eh, aquí. Vale. Y eh y ¿qué me qué más me das? Y el inferencia. Vale. Okay. Y vale. Okay. Y aquí. Vale, vamos allá. Borro. Okay. Ejecuto. Vamos allá. Vale, vamos a ver. Vale, ahora el proceso ha durado un poquito más. Bien. Y eh ahora continuación me voy a la prueba. Vamos a ver. Y en la prueba le digo, eh, ¿qué es Python? Nada. Vale. Eh, Java. Okay. ¿Qué es Java? Hola. Esto es una prueba. Esto es una pregunta. Esto es una prueba. Vale. Okay. E vamos a ver qué es la programación. Eh, pregunta del programación más es a pregunta de la programación y programación de la organización. Felicidades. Hemos programado a Mariano Rajoy en inteligencia artificial. Pero algo es algo. Vale, bien. Vamos a ver si eh vamos a poder aumentar el número de épocas. Vamos a ver. Apoc. Apo. Voy a subirlo a 200. Vamos a ver. Device traz save steps. Ok. Vale. Y vamos a darle F5. Okay. Okay. Vale, veis, con 200 épocas tarda bastante más. Es decir, le decimos, "Oye, estúdiate bien el dataset. Vamos a probarlo. Ya os digo que el dataset es pequeño. Quiero decir, la única solución no es eh aumentar las épocas, sino que la solución sería también proporcionarle un dataset más completo. Por supuesto que sí. M. Vale, ya queda poco. Que por cierto con 20 épocas ahora veremos cuáles son los tensores resultantes. Vale, eh, vamos a ver. Resultado. Okay. Checkpoint. Vale, safe tensors. Safe tensors. Vale, estamos igual. Okay. Bien. Y chatbot model. Okay. Nada. Vale, venga, pues vamos allá. F5. Vamos a verlo. Eh, Python y si Python. Python. Python. Python no. Python, no. Python, no. Vale. Okay. Em, ¿qué es Java? El har y agradable ejecutar en el har. Espérate que esto ya empieza a tener sentido. Un sentido muy lejano, sí, pero algo de sentido. ¿Qué es un algoritmo? Un algoritmo es una compra de las comprar en una construcción da y das aos y hadas y en un deber ao. Vale, se le está yendo la cabeza. Fantástico. Pero ya empezamos a tener algo, ¿vale? Es decir, conforme más vayamos aumentando, pues mejor serán los resultados. Vamos a continuar. Eh, vamos a ver porque ahora a continuación el proceso de entrenamiento, vamos a ver e please eh comment all those parameters each one of them and offer a guide into tuning those parameters to obtain a better training although costing more. Evidente. Vamos a dejar el código comentado con el tema que os decía antes del sesgo de la inteligencia artificial. Eh, claro, nosotros como seres humanos, insisto una vez más, que tenemos e pues cuestiones filosóficas que evaluar con respecto a la inteligencia artificial, tales como, por ejemplo, las siguientes. Si la inteligencia artificial analiza las actividades humanas, verá que hay actividades como desarrollador informático que lo que esa actividad la desarrollan más hombres y mujeres, o sea, hombres que mujeres. La inteligencia artificial podría llegar a la conclusión de que la programación es cosa de hombres. La pregunta es porque estadísticamente, ¿vale?, desde un punto de vista matemático estadístico, es así. Pero el problema, queremos que sea así. Es decir, ¿por qué es así? Pues porque igual quizás, no lo sé, puede ser que interese menos o puede ser que las mujeres se enfrenten a más prejuicios si se dedican al mundo de la programación. Por tanto, una cosa es lo que es y otra cosa es lo que nosotros queremos que sea. ¿Qué queremos? Queremos una sociedad mejor, queremos una sociedad más justa. Queremos una sociedad igualitaria. Queremos oportunidad, o sea, igualdad de oportunidades. Todo eso la inteligencia artificial no lo sabe, ¿vale? Por tanto, eh esas cuestiones que son unas cuestiones de sesgo y es que si la sociedad tiene injusticias y la inteligencia artificial aprende de la sociedad, la inteligencia artificial puede ser injusta, tan injusta como la sociedad. ¿Vale? Por eso, entrenar a una inteligencia artificial, os lo digo, es un proceso que no está exento de cuestiones relacionadas con la filosofía y con la ética. Vale, pues vamos a ver. Vengo por aquí y hago así, ¿vale? Eh, número total de épocas aprenda mejor. Pueden aumentar el tiempo. Fantástico. Tamaño del batch, un batch mayor, mayor estabilidad, requiere más memoria, no pasa nada. Eh, accumulation script. Esto simula un batch sin que tenga que cargar, ¿vale? Frecuencia de pasos, ¿vale? Guardados más frecuentes, no pasa nada en caso de error, eso me da igual. Save total limited, loging steps y learning rate. Valores muy altos pueden causar inestabilidad. Valores muy bajos hacer que el entrenamiento sea muy lento, ¿vale? Pequeños ajustes. Cuidado que es 3 a la5, o sea, 0.005. O sea, que y eh precisión mixta si se dispone una GPU en este caso. Sí. Vale, perfecto. Pues eh a continuación lo que voy a hacer es lo siguiente. Vamos a ver. Me voy a eh Drive y me voy a bajar mi libro de Python, uno de los libros de Python, pero vale, voy a ir a libros publicados. Voy a el de Oye, ¿dónde está? Aquí el de Python no lo veía. Le doy aquí, le doy a descargar, le doy a PDF. Claro, es que eso es lo que te digo, depende de lo que nosotros programemos, ¿vale? Eh, si tú programas a la inteligencia artificial para decirle, "No, no, esto es el set de información que yo te doy, pero tú te tienes que comportar así, así o aá o a suá." O sea, la inteligencia artificial va a hacer lo que tú le digas. La misma forma que a Deepsik no le puedes preguntar ciertas cosas de la política china, de la misma forma que a Chat GPT no le puedes preguntar ciertas cosas que son sensibles en Estados Unidos, la inteligencia artificial que tú programes hará lo que tú digas que haga. O por ejemplo, cuando tú alimentes el dataset, si tú ves preguntas y respuestas que puedes decir, mm, esta respuesta es prejuiciosa, pues la puedes quitar del dataset. Es decir, tú controlas. Es como educar un inteligente artificial es como educar un hijo. Tú eliges la información que le das y tú eliges la información que no le das en base a o tú eliges la información de cómo es la razonas. Mira, te doy esta información, pero te aclaro esto, esto y esto otro, ¿vale? O sea, que piénsalo como educar un hijo realmente. Vale, pues vamos a ver. Voy a esto y eh claro, pero no es ya que te pone la manita, sino que en el momento en el que tú tienes un JS y en el JSON hay preguntas y respuestas, tú ahí estás decidiendo qué le metes para educar a la inteligencia artificial. Y luego también te digo que como estáis viendo, pues yo hago una prueba, no me gusta, pues tuneo el parámetro, no me gusta, tuneo el parámetro. Antes de lanzarlo al público, tuneo y si me da una respuesta que en un momento dado diga, "Mm, esta respuesta no me gusta, pues igual revisaré el dataset." Es como cuando un hijo te llega y te dice algo y tú dices, eh, no, no, no, eso no es correcto, eso no lo has aprendido. Y te dice, pues es que me lo ha dicho no sé quién. y tú le dices, "No, pues desolvídate que eso no es correcto." Vale, pues lo mismo, es decir, tú intervienes ese dataset. Vale, pues eh vamos a ver carga desordenador, escritorio, ¿vale? Y digo e en base a este libro de programación eh genera un training eh un training JSON para una IA conversacional con este esquema NJSON, que ya se lo he dicho, ¿vale? ¿Dónde estás, ¿dónde estás? Aquí. Vale, en este caso pues estamos leyendo un PDF que insisto en este caso es un PDF hecho por mí, con lo cual pues estoy entrenando inteligencia artificial utilizando material mío. Podría una librería de PDF desde una biblioteca y empezar a entrenar a una inteligencia artificial con eso. Vale, pues vamos allá. Vamos a ver. Hm. Vale, pues vamos a ver qué me da. Vamos a ver. está generando. Ey, pero qué bueno, no sé. Vamos a probar a ver dataset. Vale. Eh, voy a eliminar esto. Vale, voy a ver el learning rate a la menos6. A ver qué tal. Y esto está aquí a 200. Vale, vamos a darle caña. A ver. Vale, procesador. Okay, vale. La GPU debe estar a tope porque el ventilador se me está empezando a encender, aunque el procesador no parece que tire mucho, o sea, que debe estar tirando de GPU. Vale. Okay. Vamos a ver. Ay, Vale, vamos con la prueba y voy a decir, voy a decir, voy a decir send de Python. Pregunta Sen de Python. Vale, otra vez de Python. Sen de Python. Python, ¿qué es Python? Eh, ¿cómo estás? ¿Qué cosas? Esto es una prueba. Esto es una prueba. Esto es una prueba. Vale. Eh, voy a Claro, estoy. Bueno, un momentín, estoy pensando. Vamos a una pregunta exacta. No, mira, ¿ves? Ahí está generando más contenido. Dime algo de programación. Vale, no voy a volver a entrenar. Vamos a ver. Esto lo voy a dejar a cinco y esto lo voy a pasar a 2000. Okay. Vamos a ver. Vale, mientras tanto, mientras esto se entrena, yo voy a intentar a ver si en Cloud me acepta el PDF, subir un archivo PDF y esto. Vale, está subiendo la conversación. Está al 226%. Claro. Vale. Eh, depsck, vale. Adjunto. Okay. Subiendo. Cloud, ¿cómo va? Mira, voy a voy a voy a Ubuntu eh GPU usage chart. Vamos a ver. GPU stata, pero no. Eh, Intel GPU Tools. Vale, pero bueno, ya os digo que aunque el procesador parezca que no está haciendo nada, la el ventilador me está sonando, con lo cual ya os digo yo que la GPU está a tope. A ver, un momentín. que de hecho está muy a tope. A ver, Nvidia Smi lo tendré instalado. Nvidia SMI. Okay, pues sí, vale. Y me dice que vamos a ver, tengo una 4060. Vale, ¿dónde estás? GPU name 2 GB de 8, pero no, no. Python 3 está usando 2 GB, pero no me dice el procesador, o sea, no me dice, perdón, el usage, nada. En fin, bueno, vale, pero vamos, ya os digo yo que la está usando. Vamos a ver. Y luego, efectivamente, tal y como eh tal y como comentas, al final es como el corrector automático de los teléfonos móviles, que cuando tú corriges una palabra, estás ayudando a educar a ese corrector automático y eso que tú corriges está volviendo a Apple o a Google para mejorar el resto de correctores. Vale, efectivamente, cuando tú pones una manita para arriba, una manita para abajo, le estás dando feedback acerca de si debe mejorar o de si va bien. Y luego, por otra parte, pues cada vez que yo, os fijáis que siempre le digo, "Oye, muchas gracias. Oye, está genial. Oye, no sé qué." No es solo para ayudar a educar la inteligencia artificial, sino porque quiero que me dé más de eso, ¿vale? Cuando algo me acierta le digo, "Ey, genial, me gusta, me encanta." ¿Por qué? Porque sé que guarda esa información de mí en mi cuenta y con eso se hace un perfil de lo que me gusta y lo que no me gusta. ¿Vale? Por tanto, no es que le dé las gracias porque sí, sino que le doy las gracias porque digamos que le estoy dando feedback acerca de esto no lo quiero, pero esto sí que lo quiero. Vale, este proceso, ya os digo, está tardando bastante más. Okay, ahora acabará. Venga, vale. A ver, un momento. Eh, no, esto, ¿dónde estaba yo? Aquí. Vale. Eh, results, nada. Y chatbot model 242. Parece que ocupa todavía lo mismo. Vale, que por cierto, Dipsic me lo he dejado aquí. Ah, Vale, dale. Bien. Y eh vamos a ver y probar. Vale, restart. Okay. ¿Qué es Python? Vale, está habitado para desarrollos en la medida de lo posible. es un Python de código estético, sino que desarrolles tus propias a las reglas del código hacia lo que nosotros adapte sus necesidades. Oye, ya es algo. O qué es IDL? Vamos a ver. Después de escribir el idl, que determina el código hacia la tecla del bello, que permiten crear un código bello, sino que permiten crear el código hacia la tecla F5 o O3. O3 es complejidad O3. Eso qué quiere decir, pues que ah, puede que se haya congelado la pantalla. Sí, es que ya os digo, eh, teniendo en cuenta, voy a volver a compartir, teniendo en cuenta que está usando la GPU a muerte y, evidentemente Zoom usa la GPU para representar, así que es posible que se haya quedado frito. Vale, da cuenta que con que han sido con 2000x de entrenamiento, pues oye, las respuestas todavía no son correctas, pero veis que cada vez nos estamos acercando más. Vale, vamos a ver si conseguimos un pack de entrenamiento lo más completo posible, porque ya os digo que por una parte el éxito del entrenamiento depende de aquí, ¿vale? Depende de la calidad del material de entrenamiento y por otra parte también depende de cuánto tiempo y cuántos recursos asignemos a ese entrenamiento. Vamos a verlo. Vamos a dejarle. En este caso, pues bueno, es un poco parecido a lo que estaba comentando antes Fran. Uy, espera que no había el chat. Pues yo lo que estoy haciendo es un poco como una especie de scraping, ¿vale? Lo que estoy haciendo es eh pues simplemente decirle eh al sistema que en este caso con deepsic en lugar de scrapear webs, pues oye, scrapéame mi propio libro y genera preguntas y respuestas a partir de mi propio libro. Vamos a ver. Bien, pues 20 pares. Okay. Bueno, pues suficiente de momento, eh, me vengo aquí, ¿vale? Y eh pego en data un poquito más completo, tampoco te creas que tanto, ¿vale? Y eh voy a reiniciar el proceso de entrenamiento, así que cierro por aquí y entreno por aquí y vamos a darle. Vamos a ver. Vale. Okay. ¿Veis que a medida que aumento los parámetros, pues vamos a ver, a medida que aumento los parámetros pues eh el proceso de entrenamiento dura más? Con esto lo que os quiero decir es que en este caso estamos en una clase de 6 horas donde el objetivo es pues hacer cositas en la clase de hoy, pero tampoco puedo aumentar demasiado el proceso de entrenamiento porque el proceso de entrenamiento perfectamente me puede decir, "Mira, para procesar tu libro de Python necesito una semana." Y yo le diría, "Tómate la semana, no hay ningún problema." a cambio de que luego me des unos tensores que sirvan para realmente eh hacer preguntas y respuestas. ¿Por qué? Porque yo a partir de ese momento lo que puedo hacer es generar un chatbot de José Vicente, es decir, "Oye, pregunta a José Vicente 24 horas al día." Vale, que ya le puedes preguntar a Chat GPT, evidentemente, pero digamos que si yo le entreno con mi material, pues bueno, puedes saber qué te diría José Vicente en ese caso. Y cuando digo José Vicente, lo que quiero decir es que todo este ejercicio que estamos haciendo hoy viene a demostrar que podéis no depender de Chat GPT, sino que podéis entrenar vuestra propia inteligencia artificial, o bien para vosotros o bien para el cliente que os lo pida, ¿vale? Vamos a ver, vamos a ver. Bueno, estamos a mitad de entrenamiento, ¿vale? Vamos a dejar. Ya os digo que eh aunque no esté teniendo ahora mismo una un marcador visual de cómo me está yendo la GPU, pero os digo yo que el ventilador de mi ordenador está sonando y si el ventilador de mi ordenador suena y la CPU está prácticamente sin usarse, es que es la GPU la que está calentando el ordenador. Vamos a ver. Y recordad que con todo esto pues estamos utilizando la librería de Transformers junto con otras librerías, como por ejemplo Py Torch para hacer operaciones con ayensores. ¿Vale? ¿Cuál es mi objetivo? Que juguemos un poquito con esto, ¿vale? que disfrutemos un poquito con esto y que os pique la curiosidad y que en un momento dado digáis, "Oye, si este tío está haciendo una inteligencia artificial de su libro de Python, esto quiere decir que yo puedo hacer una inteligencia artificial de un cliente de X, de un cliente de Y, de un cliente de Z. Y no, evidentemente la inteligencia artificial que vamos a hacer hoy estará a 1000 años luz de distancia de la de chat GPT. Obviamente ellos tienen años de ventaja, tienen una ventaja tecnológica enorme, por supuesto que sí, ¿vale? Pero, ¿qué pasaría si dedicáis tiempo a entrenar una inteligencia artificial? Pues vale, y luego lo segundo que quiero es que os pique la curiosidad, ¿vale? De que juguéis con esto, que comprobéis cómo funciona y que en un momento dado eso os pique para decir, "Oye, ¿cómo funcionan los tensores? ¿Cómo funcionan los Transformers? ¿Qué hay detrás de todo esto? ¿Cómo funciona esa tecnología? Vale, bien, vamos a verlo. Vamos a la fase de test y eh a ver, voy a poner por aquí a ver. Vale, creo que el primer comentario que le pongo siempre me pone el warning. Okay. Vale. Y entonces digo, eh, comentarios en Python. A ver qué me dice. Los Pythons, comprenent, capacités de código, inscribilidad, manejo de código, manejo de código, tener acto o tener rato. Manejo de código, manejo de código, cerro recomienda escribir. Tener que aceptar con obvio, tiene sentido, ¿no? Pero vale. Capacidad de código, inscribilidad. Eh, ¿qué es SQL en Python? SQL en Python es un lenguaje de datos más importantes en Nature. espera, espera, que esto se empieza a aparecer. Permite muy buena eh vez más eficiente y servicios de usar constancia para usarse. Eh, aquí hay algo. Vale, poquito a poquito nos empezamos a acercar. Muy bien. Perfecto. Me encanta. Ahora lo que quiero es eh crear un cliente. Es decir, supongamos que esto ya va empezando a estar. Ya tengo ahora mismo para probar en prueba tengo, ¿cómo te diría yo? Una línea de comando. Vale, pues quiero que cuando lance esto yo le pueda decir, "Vale, ahora vamos a generar una interfaz de usuario super guay, ¿vale? Vamos a por ello. Bien, entonces ahora a continuación eh voy a hacer lo siguiente. Vamos a ver. Me voy a chat GPT. Me voy al chat GPT, me voy al modelo O1 y digo, eh, I have this training. This trainer eh A y Python. Este es el trainer. And I have this inference test script. So please now create a web flask application. Eh, uno, create a frontend HTML CSS JS mimiking yet simplified chat GPT user interface, ¿vale? in order for the user to make questions to the AI. Vale. Send questions to backend via FCH. Make it interactive. Tres, create an endp with flask to get question. Pass it to the trained model get an answer and send it back to front. Y cuatro in front the answer and wait for the next question. Seis. Please make the application beautiful and awesome with CSS. Vamos a crear un front. Vamos a ver, ¿vale? Y de esta forma vamos a hacer como que pues el usuario pueda, ¿vale?, interactuar y de esa forma entenderéis, ojo, de una forma muy simplificada, eso que quede muy claro, pero eh entenderéis cómo funciona Chat GPT o cómo funciona de o cómo funciona cualquier inteligencia artificial, ¿vale? Que al final pues tiene un modelo preentrenado y básicamente lo que tú con lo que tú trabajas es con un front, ¿vale? con una carilla estética que te envía la pregunta al back. El back genera la respuesta en base al modelo preentrenado y te devuelve la respuesta. Vamos a ver. Eh, projecte. Vale, tenemos app.p, ¿vale? Tenemos chatbot model, tenemos templates y tenemos static y ok. Vale, bien, me gusta. Vale, pues aquí voy a ¿Dónde estás? ¿Dónde estás? Aquí. Vale, vamos a generar app.p. En app.p creamos flask, ¿vale? Eh, en templates, carpeta templates. Okay, vamos a generar index.html que vemos que tiene la llamada CSS HTML, JavaScript. Vale, fantástico. Así que index.html. Okay. Y eh y estilo.css en static y style.css. Okay. Y ya. Vale. Okay. Y esto lo tenemos. Vale. Y vamos a arrancarlo entonces. A ver, eh, ¿dónde estás, carpeta? Aquí terminal Python 3 y eh appunthon. ¿Cómo? Ah, que ha escrito mal Python. Vale, Python y local host en el puerto 5000. Vale, bueno, cualquiera de estos. Copio y aquí pego. Vamos a verlo. My O bot. Así que si todo va bien, si todo va bien, le digo, eh, dime que es Python. Envío. Okay, okay, okay. Los Python es una vez del Python y el Python los números que fumeren se pueden aparear más que la gente. Se pueden aceptar la vez la gente como Mercantil, el Python son se pueden durar los pay como os digo y que esto sirva de homenaje a don Mariano Rajoy, pero yo creo que hemos hecho una inteligencia artificial que imita Mariano Rajoy, que dice cosas sin sentido que parece que tengan sentido, pero que sin embargo no lo tienen, pero en fin, tenemos que entrenar mejor la inteligencia artificial. ¿Vale? Y ahora digo eh, ¿qué son los comentarios en Python? Le doy a enviar. Los comentarios son Python, editan, suspenses, los otros son lenguajes, se pueden modificar. Vale. Eh, ¿qué es la eh qué es SQL? Hemos preguntado antes, por ejemplo, es una relación de datos que pueden importar para quema, para quema, el esquema, la infraestructura del código y el obvio, línea, paréntesis, no se pueden importar, ¿vale? Okay. Vemos que quiere tener sentido, ¿vale? Vemos que cada vez hay más sentido en esto que estamos haciendo, ¿vale? Vamos a seguir tocando, vamos a ir seguir mejorando, vamos a ver si podemos darle un dataset más amplio para entrenar, vamos a ver si podemos entrenar con más apox. Vamos a mejorar también el front. En definitiva, vamos a ir avanzando poquito a poquito este proyecto. Bien, espero que entendáis que con lo que estamos haciendo estamos siendo totalmente independientes de APIs externas, estamos siendo totalmente independientes de proveedores externos de servicios de inteligencia artificial. Estamos creando nuestra propia inteligencia artificial. Claro, en plan purista el 1% es nuestro mérito, el 99% es mérito de la librería Transformers, ¿vale? O sea, estamos jugando como niños con la inteligencia artificial, pero lo que quiero es que juguéis, lo que quiero es que veáis que podéis para que en el futuro digáis, "Oye, quiero saber más sobre esto, quiero investigar más sobre esto, quiero aprender más sobre esto, quiero buscarme un poquito más la vida sobre esto, hacer más código, preguntarle al chat GPT, oye, ¿qué son los transformers realmente? ¿Cómo funcionan, qué hay dentro?" Y todo eso. ¿Vale? Bien. Eh, vamos a ver, vamos a ver. Eh, primero lo voy a ¿Dónde estás? El index.html. El index. HTML en templates. Vale, voy a decir que esto es, no sé, lo voy a llamar de momento HCAR Sabot. Vale, chat window messages will appear here. Vale, send enviar. Okay. Y place holder. Vale, escribe tu pregunta. Okay. Vale. Bien. Esto de momento. Vamos a procesar más. Vamos a procesar más. A ver, ¿a quién le puedo meter más caña? Si os fijáis, evidentemente, las inteligencias artificiales actuales se van a resistir un poquito a ayudarnos con el sistema de entrenamiento. ¿Por qué? Porque ahí está la gracia. Es decir, porque saben que ahí está la potencia y porque saben que ahí está la, entre comillas, la amenaza, ¿vale? La amenaza a su hegemonía. Vale, vamos a verlo y vamos a ver el chat. Vamos a ver cualquiera. También puedo preguntar a Yemini. Vamos a ver, vamos a ver. Vamos a verlo. No. Vamos a ver. Vale. Archivo JSON. Okay. Training data. Vale, vamos a verlo. Eh, training data en HTML Transformers y Data Jon. A ver qué pasa. A ver qué me ha dado reemplazar. Me estoy fiando. Me estoy fiando. No sé yo si debería. Vamos a verlo. No, aquí. Data J son recargar. Pues no. Ay, bueno, a ver. El caso es que vale, el caso es que mal no está, pero no. Eh, yes, but. I would like. the list to be as large as possible. For example, 100 questions answers in Spanish. No sé. A ver si igual le digo 100, dame 100. Y dice, "Ah, mira, pues si quieres 100 te doy 100." No lo sé. O eso o me envía la Vete saber. Pero si no lo probamos, pues evidentemente no lo vamos a saber. Vale. Vamos a dejarle que procese. Vale, de momento si no dice que no es que lo está haciendo. No. Vamos a ver. A ver, estoy pensando, estoy pensando como no sé si pasarle trozos, páginas, capítulos, no lo sé. Vamos a ver. Otra cosa es Jon to train AI questions and answers. A ver si ya hay alguno entrenado. No, no, no. Sí. Okay. Vale, pero no. No, a ver. Vamos a probar cosas o uno, ¿eh? No, aquí. A ver, cha GPT. No, vale, okay. Pero quiero muchas más en torno a 100 preguntas. Vamos a ir probando. Esto fuera. Esto fuera. Esto fuera, esto. Eh, length limit. Vale, pero okay. Yes. Need more about 1000. Deep seek. Esto es flask. Esto es el libro Drive Cloud. Eh, Transformers es Vale. Y okay. Vale, vamos a ver. 100 preguntas. Data J son. Antes eran 2,8K. Me vengo por aquí, recargo. Oh, espérate, espérate, espérate. PES.ini pip file. Yo creo que se lo ha inventado. Yo creo que se lo ha inventado porque esto no lo pongo yo en mi libro. Esto no lo pongo yo en mi libro. Esto sí, pero lo de abajo no. Vale, pero bueno, me vale. Entonces, vamos a probar chatbot model. Ahora mismo chatbot model son 240. Ah, no, 2,4 GB. espérate, espérate, espérate. Esto ya es otra cosa. Vale, 2,2 GB en resultados y aquí es 242 megas, que serán los safe tensors. Vale. Okay, perfecto. Pues hala. Elimino, entrenamos y vamos allá. Y luego eventualmente si el resto de Intelegu este no, si el resto de inteligencias artificiales van dando más datos, pues oye, los meto en el JS y bienvenidos sean. Vale, vamos a ver cómo vamos. Aquí, ¿vale? Puf, 1%. Eh, a ver, vamos a chat, ¿vale? Nueva nuevo chat. E, ¿cómo sacar una gráfica de rendimiento de la GPU en Ubuntu? Más que nada porque me gustaría que lo vierais. En Nvidia System Monitor, Nvidia SMI. Ya, pero terminal no, eh no Gnome System Monitors. Ya, pero no. GMK, una puntuación. No, no, no quiero eso. I need a eh chart like that in system monitor but for GPU. Esto en Windows está por defecto, pero en Linux no. A ver, Envidia System monitor Ubuntu, por cierto, Nvidia. Hola. Eh, sí, pero a ver, GPU 67%, mira, ahí está, 90%. Vale, por lo menos eso me empieza a valer. Thermal settings, nada. Bueno, 72 gr que no está mal. Application y vale, pues bueno, por lo menos utilización de la GPU 91%. ¿En qué? Pues en Python, evidentemente. Eh, use dedicated. Vale, okay, okay, okay. Venga, pues ya os digo, ahora mismo está el ordenador ventilando como si no hubiera un mañana. Me vengo por aquí. Madre mía. Claro, como ahora le he metido 100 preguntas, fijaos que el ritmo del proceso de entrenamiento es mucho menor que antes. Ahora veremos si las respuestas son de calidad, algo más de calidad cálculo que tendrán. Con lo cual, ¿esto qué quiere decir? Pues que como os digo, entrenar un sistema de inteligencia artificial requiere pasarse tiempo, mucho tiempo confeccionando materiales de entrenamiento y luego también requiere tiempo para que el sistema procese sus materiales, llegue a conclusiones y cree sus propios tensores, que es lo que luego utiliza para las respuestas. Vamos a verlo ahora. Luego le diré, "Oye, quiero una interfaz más chuli todavía. Vale, fijaos que para 100 preguntas, claro, porque le he puesto 2000, creo recordar, pues está tirando un buen rato. Vale, mientras tanto, otra cosa que quiero hacer es aprovechar la clase de hoy para hacer un repaso de los proyectos que hemos hecho este trimestre y por tanto los proyectos que hay que entregar, con lo cual casi que puedo aprovechar que el ordenador está procesando, está entrenando para hacer esto otro, ¿vale? Así que bueno, voy a ir empezando. Eh, voy a hacer este repaso en directo. Probablemente vosotros lo tengáis ya hecho de alguna forma, ¿vale? Lo digo porque también por el chat podéis ir participando en esto que voy a hacer. Eh, vamos a ver, voy a ir a Mediums Green, voy a ir aquí a Gokarsa. Vale, vamos a las clases de primero, ¿okay? Y vamos a ver qué hemos hecho este trimestre. en enero. Aquí, ¿vale? Aquí, si no recuerdo mal, el día eh 13 14 es cuando hicimos los exámenes, ya os digo, si no recuerdo mal, ¿o no? O yo creo que aquí debieron ser los exámenes de segundo y vosotros seríais aquí, ¿vale? Con lo cual, pues, pues eso. Bien, vamos allá. Vamos a ir ejecutando y vale esto es correo. Quieto. Vale. correo electrónico Midnight Blue. Okay, que sepáis que mi ordenador está quemando, pero bueno, vamos a apuntar por aquí en el aquí, ¿vale? y Midnight Blue eh, sistema de marketing por email. Esto estamos hablando de el día 26 de febrero. Creo recordar que por aquí antes había un tema de no de JS, ¿vale? Pero ahora hablamos de ello. Ahora volvemos atrás, ¿vale? la vender blues, ¿vale? Que es un sistema de visualización de objetos. Okay. La vender blues visualización de clases de diagramas de clases. Vale, esto sigue siendo el 26. Hot pink tenía por aquí. Vale. Okay. Hot pink. que es un sistema de conversión de formatos de archivo. Vale. Okay. Está claro. Esto es Hotpink, ¿vale? Bases de datos. Esto es la vender blu. Perfecto. Y el día siguiente, esto es Min Cream, que es un foro, que es un foro. Vale. Midnight Blue Zoro, ¿vale? Mid cream. Y esto es mi night blue. Okay. Vale, esto es semana del 26 de febrero. Estuvimos trabajando en esos proyectos, ¿vale? Midnight Blue, Lavender Blues, Hot Pink, Mint Cream. Vale, vamos a ver qué estuvimos haciendo en la semana del 4 de marzo. 4 de marzo. ¿Cómo va esto? Sigue entrenando. Le queda un rato bien. Eh, dejadme un segundín. Ya